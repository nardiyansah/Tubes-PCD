{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# baca data csv , simpan ke bentuk list\n",
    "with open(\"Fitur/area.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    # fungsi list() untuk mengubah ke bentuk list()\n",
    "    area = list(reader)[0]\n",
    "    \n",
    "with open(\"Fitur/eccentricity.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    eccentricity = list(reader)[0]\n",
    "\n",
    "with open(\"Fitur/perimeter.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    perimeter = list(reader)[0]\n",
    "    \n",
    "with open(\"Fitur/metric.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    metric = list(reader)[0]\n",
    "    \n",
    "with open(\"Fitur/red.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    red = list(reader)[0]\n",
    "    \n",
    "with open(\"Fitur/green.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    green = list(reader)[0]\n",
    "    \n",
    "with open(\"Fitur/blue.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    blue = list(reader)[0]\n",
    "\n",
    "with open(\"Fitur/blue.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    blue = list(reader)[0]\n",
    "    \n",
    "with open(\"Fitur/label.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    label = list(reader)[0]\n",
    "    \n",
    "# ganti label dalam bentuk string\n",
    "idx = 0\n",
    "for i in label:\n",
    "    if i == \"1\":\n",
    "        label[idx] = \"Cocor Bebek\"\n",
    "    elif i == \"2\":\n",
    "        label[idx] = \"Jambu\"\n",
    "    elif i == \"3\":\n",
    "        label[idx] = \"Kacang Panjang\"\n",
    "    elif i == \"4\":\n",
    "        label[idx] = \"Singkong\"\n",
    "    elif i == \"5\":\n",
    "        label[idx] = \"Tomat\"\n",
    "        \n",
    "    idx = idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# fungsi map() untuk mengubah tipe data semua element dalam list\n",
    "# fungsi zip() untuk menggandengkan setiap list menjadi matriks\n",
    "df = pd.DataFrame(list(zip(list(map(int,area)), list(map(float,eccentricity)), list(map(float,perimeter)), list(map(float,metric)), list(map(float,red)), list(map(float,green)), list(map(float,blue)), label)), columns = ['Area', 'Eccentricity', 'Perimeter', 'Metric', 'Red', 'Green', 'Blue', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Red</th>\n",
       "      <th>Green</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2592</td>\n",
       "      <td>0.587480</td>\n",
       "      <td>648.558</td>\n",
       "      <td>0.077437</td>\n",
       "      <td>62.147971</td>\n",
       "      <td>98.496181</td>\n",
       "      <td>34.956567</td>\n",
       "      <td>Tomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2034</td>\n",
       "      <td>0.744930</td>\n",
       "      <td>296.505</td>\n",
       "      <td>0.290735</td>\n",
       "      <td>48.569492</td>\n",
       "      <td>67.977778</td>\n",
       "      <td>38.859887</td>\n",
       "      <td>Tomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1796</td>\n",
       "      <td>0.736844</td>\n",
       "      <td>262.322</td>\n",
       "      <td>0.327980</td>\n",
       "      <td>82.097821</td>\n",
       "      <td>107.617685</td>\n",
       "      <td>66.557027</td>\n",
       "      <td>Tomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1931</td>\n",
       "      <td>0.789033</td>\n",
       "      <td>542.651</td>\n",
       "      <td>0.082404</td>\n",
       "      <td>62.952130</td>\n",
       "      <td>88.649493</td>\n",
       "      <td>54.805680</td>\n",
       "      <td>Tomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1787</td>\n",
       "      <td>0.792165</td>\n",
       "      <td>525.614</td>\n",
       "      <td>0.081283</td>\n",
       "      <td>80.768362</td>\n",
       "      <td>111.433290</td>\n",
       "      <td>70.402434</td>\n",
       "      <td>Tomat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Eccentricity  Perimeter    Metric        Red       Green       Blue  \\\n",
       "95  2592      0.587480    648.558  0.077437  62.147971   98.496181  34.956567   \n",
       "96  2034      0.744930    296.505  0.290735  48.569492   67.977778  38.859887   \n",
       "97  1796      0.736844    262.322  0.327980  82.097821  107.617685  66.557027   \n",
       "98  1931      0.789033    542.651  0.082404  62.952130   88.649493  54.805680   \n",
       "99  1787      0.792165    525.614  0.081283  80.768362  111.433290  70.402434   \n",
       "\n",
       "    Label  \n",
       "95  Tomat  \n",
       "96  Tomat  \n",
       "97  Tomat  \n",
       "98  Tomat  \n",
       "99  Tomat  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melihat 5 data terakhir, sekedar melihat struktur tabel\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memisahkan data ke train dan test\n",
    "train_dataset = df.sample(frac=0.8, random_state=0)\n",
    "test_dataset = df.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memisahkan label\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "# pd.get_dummies() untuk membuat one-hot encoding\n",
    "train_labels = pd.get_dummies(train_features.pop('Label'))\n",
    "test_labels = pd.get_dummies(test_features.pop('Label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cocor Bebek  Jambu  Kacang Panjang  Singkong  Tomat\n",
      "9             1      0               0         0      0\n",
      "12            1      0               0         0      0\n",
      "21            0      1               0         0      0\n",
      "25            0      1               0         0      0\n",
      "36            0      1               0         0      0\n",
      "37            0      1               0         0      0\n",
      "39            0      1               0         0      0\n",
      "44            0      0               1         0      0\n",
      "46            0      0               1         0      0\n",
      "47            0      0               1         0      0\n",
      "58            0      0               1         0      0\n",
      "64            0      0               0         1      0\n",
      "65            0      0               0         1      0\n",
      "67            0      0               0         1      0\n",
      "70            0      0               0         1      0\n",
      "81            0      0               0         0      1\n",
      "83            0      0               0         0      1\n",
      "87            0      0               0         0      1\n",
      "88            0      0               0         0      1\n",
      "96            0      0               0         0      1\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# membuat normalization layer\n",
    "normalizer = preprocessing.Normalization()\n",
    "\n",
    "normalizer.adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example: [[3843.      0.78  846.89    0.07   41.99   85.28   22.97]]\n",
      "\n",
      "Normalized: [[ 0.88 -0.2   2.27 -1.38 -1.12  0.66 -0.62]]\n"
     ]
    }
   ],
   "source": [
    "first = np.array(train_features[:1])\n",
    "# mengecek apak normalization layer sudah berfungsi\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print('First example:',first)\n",
    "    print()\n",
    "    print('Normalized:', normalizer(first).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(normalizer)\n",
    "model.add(layers.Dense(14, input_dim=7, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 1.6146 - accuracy: 0.3281 - val_loss: 1.9780 - val_accuracy: 0.1250\n",
      "Epoch 2/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5616 - accuracy: 0.3281 - val_loss: 1.9421 - val_accuracy: 0.1875\n",
      "Epoch 3/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5137 - accuracy: 0.3438 - val_loss: 1.9029 - val_accuracy: 0.1875\n",
      "Epoch 4/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4671 - accuracy: 0.3438 - val_loss: 1.8695 - val_accuracy: 0.1875\n",
      "Epoch 5/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4260 - accuracy: 0.3438 - val_loss: 1.8365 - val_accuracy: 0.2500\n",
      "Epoch 6/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3815 - accuracy: 0.3750 - val_loss: 1.8042 - val_accuracy: 0.2500\n",
      "Epoch 7/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3431 - accuracy: 0.3750 - val_loss: 1.7783 - val_accuracy: 0.2500\n",
      "Epoch 8/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3056 - accuracy: 0.3906 - val_loss: 1.7482 - val_accuracy: 0.1875\n",
      "Epoch 9/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2698 - accuracy: 0.3906 - val_loss: 1.7187 - val_accuracy: 0.1875\n",
      "Epoch 10/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2356 - accuracy: 0.4062 - val_loss: 1.6946 - val_accuracy: 0.1875\n",
      "Epoch 11/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2028 - accuracy: 0.4062 - val_loss: 1.6714 - val_accuracy: 0.1875\n",
      "Epoch 12/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1715 - accuracy: 0.4062 - val_loss: 1.6515 - val_accuracy: 0.2500\n",
      "Epoch 13/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1412 - accuracy: 0.4375 - val_loss: 1.6324 - val_accuracy: 0.2500\n",
      "Epoch 14/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1122 - accuracy: 0.5938 - val_loss: 1.6142 - val_accuracy: 0.2500\n",
      "Epoch 15/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0847 - accuracy: 0.6250 - val_loss: 1.5963 - val_accuracy: 0.2500\n",
      "Epoch 16/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0580 - accuracy: 0.6562 - val_loss: 1.5785 - val_accuracy: 0.2500\n",
      "Epoch 17/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0325 - accuracy: 0.6875 - val_loss: 1.5602 - val_accuracy: 0.3125\n",
      "Epoch 18/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0068 - accuracy: 0.6719 - val_loss: 1.5422 - val_accuracy: 0.3125\n",
      "Epoch 19/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.9826 - accuracy: 0.6875 - val_loss: 1.5205 - val_accuracy: 0.3750\n",
      "Epoch 20/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.9577 - accuracy: 0.7188 - val_loss: 1.4969 - val_accuracy: 0.4375\n",
      "Epoch 21/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.9344 - accuracy: 0.7031 - val_loss: 1.4789 - val_accuracy: 0.4375\n",
      "Epoch 22/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.9120 - accuracy: 0.7188 - val_loss: 1.4603 - val_accuracy: 0.3750\n",
      "Epoch 23/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8900 - accuracy: 0.7344 - val_loss: 1.4421 - val_accuracy: 0.3750\n",
      "Epoch 24/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8701 - accuracy: 0.7656 - val_loss: 1.4231 - val_accuracy: 0.4375\n",
      "Epoch 25/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8482 - accuracy: 0.7969 - val_loss: 1.4062 - val_accuracy: 0.4375\n",
      "Epoch 26/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8295 - accuracy: 0.7969 - val_loss: 1.3876 - val_accuracy: 0.3750\n",
      "Epoch 27/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8097 - accuracy: 0.8281 - val_loss: 1.3734 - val_accuracy: 0.4375\n",
      "Epoch 28/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7907 - accuracy: 0.8438 - val_loss: 1.3557 - val_accuracy: 0.5000\n",
      "Epoch 29/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7725 - accuracy: 0.8594 - val_loss: 1.3411 - val_accuracy: 0.5000\n",
      "Epoch 30/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7541 - accuracy: 0.8594 - val_loss: 1.3239 - val_accuracy: 0.5000\n",
      "Epoch 31/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7368 - accuracy: 0.8750 - val_loss: 1.3071 - val_accuracy: 0.5000\n",
      "Epoch 32/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7197 - accuracy: 0.8906 - val_loss: 1.2921 - val_accuracy: 0.5000\n",
      "Epoch 33/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7026 - accuracy: 0.8906 - val_loss: 1.2787 - val_accuracy: 0.5000\n",
      "Epoch 34/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.9062 - val_loss: 1.2664 - val_accuracy: 0.5625\n",
      "Epoch 35/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.9062 - val_loss: 1.2543 - val_accuracy: 0.5625\n",
      "Epoch 36/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.9219 - val_loss: 1.2412 - val_accuracy: 0.5625\n",
      "Epoch 37/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.9219 - val_loss: 1.2303 - val_accuracy: 0.5625\n",
      "Epoch 38/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.9219 - val_loss: 1.2210 - val_accuracy: 0.6250\n",
      "Epoch 39/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.9219 - val_loss: 1.2079 - val_accuracy: 0.6875\n",
      "Epoch 40/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.9219 - val_loss: 1.1986 - val_accuracy: 0.6875\n",
      "Epoch 41/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.9219 - val_loss: 1.1882 - val_accuracy: 0.7500\n",
      "Epoch 42/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.9219 - val_loss: 1.1798 - val_accuracy: 0.7500\n",
      "Epoch 43/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.9219 - val_loss: 1.1707 - val_accuracy: 0.8125\n",
      "Epoch 44/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.9219 - val_loss: 1.1607 - val_accuracy: 0.8125\n",
      "Epoch 45/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.9219 - val_loss: 1.1536 - val_accuracy: 0.8125\n",
      "Epoch 46/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.9219 - val_loss: 1.1454 - val_accuracy: 0.8125\n",
      "Epoch 47/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.9219 - val_loss: 1.1385 - val_accuracy: 0.8125\n",
      "Epoch 48/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.9219 - val_loss: 1.1294 - val_accuracy: 0.8125\n",
      "Epoch 49/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.9219 - val_loss: 1.1234 - val_accuracy: 0.8125\n",
      "Epoch 50/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.9062 - val_loss: 1.1164 - val_accuracy: 0.8125\n",
      "Epoch 51/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.9062 - val_loss: 1.1126 - val_accuracy: 0.8125\n",
      "Epoch 52/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.9219 - val_loss: 1.1075 - val_accuracy: 0.8125\n",
      "Epoch 53/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.9375 - val_loss: 1.1008 - val_accuracy: 0.8125\n",
      "Epoch 54/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.9531 - val_loss: 1.0951 - val_accuracy: 0.8125\n",
      "Epoch 55/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.9531 - val_loss: 1.0879 - val_accuracy: 0.8125\n",
      "Epoch 56/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.9531 - val_loss: 1.0837 - val_accuracy: 0.8125\n",
      "Epoch 57/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.9531 - val_loss: 1.0787 - val_accuracy: 0.8125\n",
      "Epoch 58/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.9531 - val_loss: 1.0757 - val_accuracy: 0.8125\n",
      "Epoch 59/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.9531 - val_loss: 1.0690 - val_accuracy: 0.8125\n",
      "Epoch 60/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.9531 - val_loss: 1.0648 - val_accuracy: 0.8125\n",
      "Epoch 61/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.9531 - val_loss: 1.0618 - val_accuracy: 0.8125\n",
      "Epoch 62/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.9531 - val_loss: 1.0587 - val_accuracy: 0.8125\n",
      "Epoch 63/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.9531 - val_loss: 1.0568 - val_accuracy: 0.8125\n",
      "Epoch 64/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.9531 - val_loss: 1.0546 - val_accuracy: 0.8125\n",
      "Epoch 65/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.9531 - val_loss: 1.0510 - val_accuracy: 0.8125\n",
      "Epoch 66/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.9531 - val_loss: 1.0479 - val_accuracy: 0.8125\n",
      "Epoch 67/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.9531 - val_loss: 1.0462 - val_accuracy: 0.8125\n",
      "Epoch 68/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.9688 - val_loss: 1.0458 - val_accuracy: 0.8125\n",
      "Epoch 69/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.9688 - val_loss: 1.0443 - val_accuracy: 0.8125\n",
      "Epoch 70/80\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.9688 - val_loss: 1.0405 - val_accuracy: 0.8125\n",
      "Epoch 71/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.9688 - val_loss: 1.0416 - val_accuracy: 0.8125\n",
      "Epoch 72/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.9688 - val_loss: 1.0418 - val_accuracy: 0.8125\n",
      "Epoch 73/80\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.9688 - val_loss: 1.0402 - val_accuracy: 0.8125\n",
      "Epoch 74/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.9688 - val_loss: 1.0377 - val_accuracy: 0.8125\n",
      "Epoch 75/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.9688 - val_loss: 1.0369 - val_accuracy: 0.8125\n",
      "Epoch 76/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.9688 - val_loss: 1.0349 - val_accuracy: 0.8125\n",
      "Epoch 77/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.9688 - val_loss: 1.0362 - val_accuracy: 0.8125\n",
      "Epoch 78/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9688 - val_loss: 1.0356 - val_accuracy: 0.8125\n",
      "Epoch 79/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.9688 - val_loss: 1.0343 - val_accuracy: 0.8125\n",
      "Epoch 80/80\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9688 - val_loss: 1.0362 - val_accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_features, y=train_labels, batch_size=5, epochs=80, shuffle=True, validation_split=0.2)\n",
    "\n",
    "epochs = history.epoch\n",
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.9500\n",
      "test loss, test acc: [0.5055637359619141, 0.949999988079071]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_features, test_labels, batch_size=4)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([2592, 0.587480, 648.558, 0.077437, 62.147971, 98.496181, 34.956567])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [9.9974889e-01 1.2922240e-05 6.1844061e-05 1.7642787e-04 2.6401832e-12]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.6495037e-03 1.4389096e-06 1.0276807e-01 8.9357835e-01 2.7010733e-06]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocor = 0\n",
    "jambu = 0\n",
    "kacang = 0\n",
    "singkong = 0\n",
    "tomat = 0\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(5):\n",
    "        if j == 0:\n",
    "            cocor += prediction[i][j]\n",
    "        elif j == 1:\n",
    "            jambu += prediction[i][j]\n",
    "        elif j == 2:\n",
    "            kacang += prediction[i][j]\n",
    "        elif j == 3:\n",
    "            singkong += prediction[i][j]\n",
    "        elif j == 4:\n",
    "            tomat += prediction[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0033983893226832\n",
      "5.0000143611495105\n",
      "0.1028299150566454\n",
      "0.8937547784153139\n",
      "2.7010759394326123e-06\n"
     ]
    }
   ],
   "source": [
    "print(cocor)\n",
    "print(jambu)\n",
    "print(kacang)\n",
    "print(singkong)\n",
    "print(tomat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
